---
title: purg ~ Purgatory Edit, methodology
layout: content
tags: resource
pubdate: January 1, 2017 12:00 AM
unlisted: "true"
summary: "**Purgatory Edit** (working title) proposes to use the Emotive Epoc+,
  a head-mounted home MRI kit and a wireless EEG gear that allows a ‘reading’ of
  the viewer’s semiconscious mind-states, abstract emotions such as frustration,
  anxiety, excitement, meditation, etc. and translates it into as numerical
  values. These values are fed into VDMX, a VJ software, to generate an
  algorithm based real-time stitching of a ‘string’ of videos/images from the
  two databanks and uses this data as parameters to control the flow of video
  sequence."
parent: " Purgatory Edit"
---
![](/static/img/purgatory-edit-pipeline-map-colour.png)

## Methodology



1. ### Archive

PURGATORY EDIT examines the power of hegemonic representation within historical, visual, and cinematic vocabularies through an archive compiled by collecting hundreds of video clips ranging from archival war footage, cinema, documentary, advertisements, news, landscape panoramas, and home videos. It performs a conceptual vocabulary analysis of keywords like ‘war’ and ‘peace’, ‘violence’ and ‘conflict’, as used within moving image media. Creating this archive includes a digital processing tasks such as:

* Conducting research on types of video clips to be sourced
* Sourcing video footage, sorting and categorising them
* Designing an intensity map: used for categorisation and for the coding team as a spectrum reference 
* Generating metadata and tagging media clips according to intensity map
* Slicing footage to extract required clips
* Equalise resolution, aspect ratio, formatting, and colour correction discrepancies
* Additional treatment of redundant media, such as noise removal and footage cleaning

  <br/>

2. ### Analysis

This archive will serve as source material to conduct a ‘conceptual visual vocabulary analysis’ and study keywords like ‘war’, ‘peace’, ‘violence’, ‘conflict’ through the intersectional lens of violence and conflict resolution, neocolonialism, data hegemony and power relations. Such a study is essential to reveal how such concepts are used and represented within moving image media such as documentary, video, and cinema. 

* Categorise the types of violence represented in this archive, working together with Cognitive Behaviour and Neuroscience specialists
* Create a violence intensity map

  <br/>

3. ### System design and code dev.

The study facilitates the second phase of the project, the performance installation where the videos are categorised and organised into multiple video types as data banks, broadly divided into ‘War’, and ‘Peace’.

Together with UX Designer and programmer Palash Mukhopadhyay, I will develop proprietary software to utilise ‘Emotiv Epoc X’ – a wireless head-mounted home MRI & EEG medical kit designed to ‘read’ a user’s semi-conscious mind-state, represented as abstract emotions such as frustration, anxiety, excitement, meditation – and translate them into numerical values. 

With this software, we will use these values as parameters that allow VUO, a popular VJ software, to generate an algorithm-based real-time stitching of a ‘string’ of videos from the video data banks. Through this built software and the Emotiv Epoc X hardware, participants’ brainwaves will be able to control a real-time juxtaposition of a pre-compiled and curated string of videos – its sequencing, intensities and specific types of video, as well as playback speed, fluctuations, and designed glitches. 

* Designing a bridge system that can read Emotiv generated values as parameters
* Linking parameters to: 
* * sequencing of video playback
  * frequency and rate of changing footage
  * video type selection (intensity map) as well as playback speed, fluctuations, and designed glitches. 
* Developing code for generating ‘procedural glitch’ on processed media
* Creating an organisation system (database) to sort media 

  <br/>

4. #### Installation development

Finally, a virtual Cinema space is created using Unity, a VR software, where the real-time sequence generated by the participant is played out.